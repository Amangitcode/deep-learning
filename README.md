# Overview
In-depth dive into neural nets, deep nets, CNN's, RNN's, face recognition, neural style transfer, object detection and structuring/debugging machine learning projects. Coded using Python 3, numpy, and TensorFlow through Jupyter Notebook
Deep Learning Specialization taught by Andrew Ng.
## Course 1: Neural Networks & Deep Learning
### Topics Covered:
- Why is Deep Learning Taking Off?
- Logistic Regression
- Shallow vs Deep Neural Networks (few layers)
- Vectorization
- Activation Functions
- Random Initialization

## Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization
### Topics Covered:
- Train/Dev/Test Sets
- Basic Recipe for Machine Learning
- Regularization
- Data Augmentation
- Early Stopping
- Gradient Checking
- Gradient Descent with Momentum
- RMSProp (root mean square)
	- Divide gradients by exponentially weighted moving average, thereby making large gradients which usually osccilate update less and small gradients which usually don't osccilate update more.
- Adam Optimization (adaptive moment estimation)
- Learning Rate Decay
- Local Optima
- Hyperparamater tuning
- Approriate Scale of HyperParameters
- Batch Normalization
- Batch Norm @ Test Time
- Multi-Class Classification

## Course 3: Structuring Machine Learning Projects
### Topics Covered:
- Orthogonalization
- Single Number Evaluation Metrics
- Satisficing and Optimising Metrics
- Train/Dev/Test Distribution
-Dev and Test Set Size
- When to change dev/test set and metrics
- Human Level Performance
- Improving your Model Performance
- Error Analysis
- Cleaning up incorrectly Labelled Errors
- Build system quickly and then iterate
- Different Test/Dev Set Distributions
- Data Mismatch, Bias and Variance with Mismatched Data Distributions
- Addressing Data Mismatch
- Transfer Learning detection
- Multi-task Learning
- End-To-End Learning

### Technical Skills Acquired:
- Python 3.0
  - numpy
  - Tensorflow
